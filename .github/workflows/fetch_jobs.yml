name: Daily Job Data Fetch

on:
  schedule:
    - cron: "0 17 * * *"
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Tokyo  
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "google-search-results>=2.4.2" openai c pandas supabase python-dateutil requests

      - name: Run scraping script
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
          SERPAPI_KEY: ${{ secrets.SERPAPI_KEY }}
          AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
          AZURE_OPENAI_KEY: ${{ secrets.AZURE_OPENAI_KEY }}
        run: |
          python analysis/scrape_jobs.py
